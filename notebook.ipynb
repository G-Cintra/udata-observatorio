{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import logging \n",
    "import requests\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "diretorio_dados = 'dados'\n",
    "diretorio_dados_processados = os.path.join(diretorio_dados, \"processados\")\n",
    "diretorio_imagens = 'imagens'\n",
    "arquivo_csv = \"merged_data.csv\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reset_logger(logger_name, log_file_path):\n",
    "    \"\"\"\n",
    "    Resets the logger by removing handlers, clearing the log file, \n",
    "    and reinitializing the logger.\n",
    "    \n",
    "    Parameters:\n",
    "        logger_name (str): The name of the logger to reset.\n",
    "        log_file_path (str): Path to the log file to clear and reuse.\n",
    "    \"\"\"\n",
    "    logger = logging.getLogger(logger_name)\n",
    "    \n",
    "    # Remove and close all handlers\n",
    "    for handler in logger.handlers[:]:\n",
    "        handler.close()\n",
    "        logger.removeHandler(handler)\n",
    "    \n",
    "    # Clear the log file\n",
    "    with open(log_file_path, \"w\", encoding=\"utf-8\") as log_file:\n",
    "        log_file.write(\"\")\n",
    "    \n",
    "    # Reinitialize the logger\n",
    "    logging.basicConfig(\n",
    "        filename=log_file_path,\n",
    "        level=logging.INFO,\n",
    "        format=\"%(asctime)s - %(levelname)s - %(message)s\",\n",
    "        encoding=\"utf-8\"\n",
    "    )\n",
    "    \n",
    "# Nome do logger e caminho do arquivo de log\n",
    "logger_name = \"root\"  # Nome do logger padrão\n",
    "arquivo_log = \"dados_alterados.log\"\n",
    "\n",
    "# Configurar o logger inicialmente\n",
    "logging.basicConfig(\n",
    "    filename=arquivo_log,\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s - %(levelname)s - %(message)s\",\n",
    "    encoding=\"utf-8\"\n",
    ")\n",
    "\n",
    "logging.info(\"Logger inicializado.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finalizar o logger e fechar o arquivo de log\n",
    "for handler in logging.root.handlers[:]:\n",
    "    handler.close()\n",
    "    logging.root.removeHandler(handler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para buscar dados da API do Banco Central\n",
    "def fetch_bcb_series(series_code, start_date, end_date=None):\n",
    "    \"\"\"\n",
    "    Busca uma série do Banco Central do Brasil usando a API SGS.\n",
    "    \n",
    "    Args:\n",
    "        series_code (int): Código da série.\n",
    "        start_date (str): Data de início no formato DD/MM/AAAA.\n",
    "        end_date (str): Data de fim no formato DD/MM/AAAA (default: hoje).\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame com as datas e valores da série.\n",
    "    \"\"\"\n",
    "    if end_date is None:\n",
    "        end_date = datetime.today().strftime('%d/%m/%Y')\n",
    "    \n",
    "    url = f\"https://api.bcb.gov.br/dados/serie/bcdata.sgs.{series_code}/dados\"\n",
    "    params = {\"formato\": \"json\", \"dataInicial\": start_date, \"dataFinal\": end_date}\n",
    "    print(url)\n",
    "    print(params)\n",
    "    response = requests.get(url, params=params)\n",
    "    response.raise_for_status()\n",
    "    \n",
    "    data = response.json()\n",
    "    df = pd.DataFrame(data)\n",
    "    df['data'] = pd.to_datetime(df['data'], format='%d/%m/%Y')\n",
    "    df['valor'] = pd.to_numeric(df['valor'], errors='coerce')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lista de séries do BCB e seus códigos\n",
    "bcb_series = [\n",
    "    { \n",
    "        \"Nome\": \"Selic\",\n",
    "        \"Descrição\" : \"Taxa de juros que representa a taxa média ajustada das operações compromissadas com prazo de um dia útil lastreadas com títulos públicos federais custodiados no Sistema Especial de Liquidação e de Custódia (Selic). Divulgação em % a.d.\",\n",
    "        \"Série\": 11,\n",
    "    },\n",
    "    { \n",
    "        \"Nome\": \"Taxa de Juros PF\",\n",
    "        \"Descrição\" : \"Taxa de juros que representa a taxa média ajustada das operações compromissadas com prazo de um dia útil lastreadas com títulos públicos federais custodiados no Sistema Especial de Liquidação e de Custódia (Selic). Divulgação em % a.d.\",\n",
    "        \"Série\": 11,\n",
    "    },\n",
    "    {\n",
    "        \"Nome\": \"Spread médio PF\",\n",
    "        \"Descrição\": \"Diferença entre a taxa média de juros das novas operações de crédito livre contratadas no período de referência e o custo de captação referencial médio. Não inclui operações referenciadas em taxas regulamentadas, operações vinculadas a recursos do Banco Nacional de Desenvolvimento Econômico e Social (BNDES) ou quaisquer outras lastreadas em recursos compulsórios ou governamentais.\",\n",
    "        \"Série\": 20809,\n",
    "    },\n",
    "    {\n",
    "        \"Nome\": \"Concessões de crédito PF\",\n",
    "        \"Descrição\": \"Conceito: Valor das novas operações de crédito contratadas no período de referência com taxas de juros livremente pactuadas entre mutuários e instituições financeiras. Não inclui operações referenciadas em taxas regulamentadas, operações vinculadas a recursos do Banco Nacional de Desenvolvimento Econômico e Social (BNDES) ou quaisquer outras lastreadas em recursos compulsórios ou governamentais.\",\n",
    "        \"Série\": 20662,\n",
    "    },\n",
    "    {\n",
    "        \"Nome\": \"Inadimplência da carteira de crédito PF\",\n",
    "        \"Descrição\": \"Conceito: Percentual da carteira de crédito do Sistema Financeiro Nacional com pelo menos uma parcela com atraso superior a 90 dias. Inclui operações contratadas no segmento de crédito livre e no segmento de crédito direcionado.\",\n",
    "        \"Série\": 21084,\n",
    "    },\n",
    "    {\n",
    "        \"Nome\": \"Captação líquida diária de depósitos de poupança - SBPE\",\n",
    "        \"Descrição\": \"A captação líquida é representada pela soma das aplicações e dos rendimentos creditados, excluindo-se as retiradas\",\n",
    "        \"Série\": 240,\n",
    "    },\n",
    "    {\n",
    "        \"Nome\": \"Saldo diário de depósitos de poupança - SBPE e rural\",\n",
    "        \"Descrição\": \"Saldo diário de depósitos de poupança - SBPE e rural\",\n",
    "        \"Série\": 23,\n",
    "    },\n",
    "    {\n",
    "        \"Nome\": \"Índice de Confiança do Consumidor\",\n",
    "        \"Descrição\": \"O Índice de Confiança do Consumidor (ICC) busca identificar o sentimento dos consumidores relativo às suas condições financeiras, às suas perspectivas futuras e também a percepção que o consumidor tem das condições econômicas do país.\",\n",
    "        \"Série\": 4393,\n",
    "    },\n",
    "    {\n",
    "        \"Nome\": \"Índice nacional de preços ao consumidor-amplo (IPCA)\",\n",
    "        \"Descrição\": \"O IPCA tem por objetivo medir a inflação de um conjunto de produtos e serviços comercializados no varejo, referentes ao consumo pessoal das famílias. Para garantir uma cobertura de 90% das famílias das áreas urbanas do País, abrange atualmente aquelas com rendimentos de 1 a 40 salários mínimos nas regiões metropolitanas de Belém, Fortaleza, Recife, Salvador, Belo Horizonte, Vitória, Rio de Janeiro, São Paulo, Curitiba e Porto Alegre, além do Distrito Federal e dos municípios de Goiânia, Campo Grande, Rio Branco, São Luís e Aracaju. (Var. % mensal) \",\n",
    "        \"Série\": 433,\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baixando série do BCB: Selic (Código: 11)\n",
      "https://api.bcb.gov.br/dados/serie/bcdata.sgs.11/dados\n",
      "{'formato': 'json', 'dataInicial': '01/01/2000', 'dataFinal': '12/11/2024'}\n",
      "Arquivo salvo: dados\\BCB Selic - COD11 - 20241112144802.csv\n",
      "Baixando série do BCB: Taxa de Juros PF (Código: 11)\n",
      "https://api.bcb.gov.br/dados/serie/bcdata.sgs.11/dados\n",
      "{'formato': 'json', 'dataInicial': '01/01/2000', 'dataFinal': '12/11/2024'}\n",
      "Arquivo salvo: dados\\BCB Taxa de Juros PF - COD11 - 20241112144802.csv\n",
      "Baixando série do BCB: Spread médio PF (Código: 20809)\n",
      "https://api.bcb.gov.br/dados/serie/bcdata.sgs.20809/dados\n",
      "{'formato': 'json', 'dataInicial': '01/01/2000', 'dataFinal': '12/11/2024'}\n",
      "Arquivo salvo: dados\\BCB Spread médio PF - COD20809 - 20241112144803.csv\n",
      "Baixando série do BCB: Concessões de crédito PF (Código: 20662)\n",
      "https://api.bcb.gov.br/dados/serie/bcdata.sgs.20662/dados\n",
      "{'formato': 'json', 'dataInicial': '01/01/2000', 'dataFinal': '12/11/2024'}\n",
      "Arquivo salvo: dados\\BCB Concessões de crédito PF - COD20662 - 20241112144803.csv\n",
      "Baixando série do BCB: Inadimplência da carteira de crédito PF (Código: 21084)\n",
      "https://api.bcb.gov.br/dados/serie/bcdata.sgs.21084/dados\n",
      "{'formato': 'json', 'dataInicial': '01/01/2000', 'dataFinal': '12/11/2024'}\n",
      "Arquivo salvo: dados\\BCB Inadimplência da carteira de crédito PF - COD21084 - 20241112144803.csv\n",
      "Baixando série do BCB: Captação líquida diária de depósitos de poupança - SBPE (Código: 240)\n",
      "https://api.bcb.gov.br/dados/serie/bcdata.sgs.240/dados\n",
      "{'formato': 'json', 'dataInicial': '01/01/2000', 'dataFinal': '12/11/2024'}\n",
      "Arquivo salvo: dados\\BCB Captação líquida diária de depósitos de poupança - SBPE - COD240 - 20241112144804.csv\n",
      "Baixando série do BCB: Saldo diário de depósitos de poupança - SBPE e rural (Código: 23)\n",
      "https://api.bcb.gov.br/dados/serie/bcdata.sgs.23/dados\n",
      "{'formato': 'json', 'dataInicial': '01/01/2000', 'dataFinal': '12/11/2024'}\n",
      "Arquivo salvo: dados\\BCB Saldo diário de depósitos de poupança - SBPE e rural - COD23 - 20241112144810.csv\n",
      "Baixando série do BCB: Índice de Confiança do Consumidor (Código: 4393)\n",
      "https://api.bcb.gov.br/dados/serie/bcdata.sgs.4393/dados\n",
      "{'formato': 'json', 'dataInicial': '01/01/2000', 'dataFinal': '12/11/2024'}\n",
      "Arquivo salvo: dados\\BCB Índice de Confiança do Consumidor - COD4393 - 20241112144811.csv\n",
      "Baixando série do BCB: Índice nacional de preços ao consumidor-amplo (IPCA) (Código: 433)\n",
      "https://api.bcb.gov.br/dados/serie/bcdata.sgs.433/dados\n",
      "{'formato': 'json', 'dataInicial': '01/01/2000', 'dataFinal': '12/11/2024'}\n",
      "Arquivo salvo: dados\\BCB Índice nacional de preços ao consumidor-amplo (IPCA) - COD433 - 20241112144811.csv\n"
     ]
    }
   ],
   "source": [
    "# Data inicial para busca\n",
    "start_date = \"01/01/2000\"\n",
    "\n",
    "# Loop para buscar todas as séries do BCB\n",
    "for item in bcb_series:\n",
    "    name = item[\"Nome\"]\n",
    "    code = item[\"Série\"]\n",
    "    print(f\"Baixando série do BCB: {name} (Código: {code})\")\n",
    "    df = fetch_bcb_series(code, start_date)\n",
    "    df = df.rename(columns={\"valor\": name})\n",
    "    filename = f\"BCB {name} - COD{code} - {datetime.today().strftime('%Y%m%d%H%M%S')}.csv\"\n",
    "    filename = os.path.join(diretorio_dados, filename)\n",
    "    df.to_csv(filename, index=False)\n",
    "    print(f\"Arquivo salvo: {filename}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para buscar dados da API do IBGE (SIDRA)\n",
    "def fetch_ibge_series(table_id, variable_id, period=\"all\"):\n",
    "    \"\"\"\n",
    "    Busca dados do IBGE usando a API SIDRA.\n",
    "    \n",
    "    Args:\n",
    "        table_id (int): Código da tabela no SIDRA.\n",
    "        variable_id (int): Código da variável na tabela.\n",
    "        period (str): Período de busca (default: \"all\").\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame com os dados da série.\n",
    "    \"\"\"\n",
    "    url = f\"https://apisidra.ibge.gov.br/values/t/{table_id}/v/{variable_id}/p/{period}/N1/1\"\n",
    "    response = requests.get(url)\n",
    "    response.raise_for_status()\n",
    "    data = response.json()\n",
    "    print(url)\n",
    "    \n",
    "    # Converter JSON para DataFrame\n",
    "    df = pd.DataFrame(data[1:])  # Ignora o cabeçalho\n",
    "    df['data'] = pd.to_datetime(df['D2C'].str[:4] + '-' + (df['D2C'].str[4:].astype(int) * 3 - 2).astype(str), format='%Y-%m')\n",
    "    df['valor'] = pd.to_numeric(df['V'], errors='coerce')\n",
    "    return df[['data', 'valor']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baixando série do IBGE: Índice de Desemprego (Tabela: 4094, Variável: 4098)\n",
      "https://apisidra.ibge.gov.br/values/t/4094/v/4098/p/all/N1/1\n",
      "Arquivo salvo: dados\\IBGE Índice de Desemprego - T4094 - V4098 - 20241112144928.csv\n"
     ]
    }
   ],
   "source": [
    "# Lista de séries do IBGE e suas tabelas/variáveis\n",
    "ibge_series = {\n",
    "    \"Índice de Desemprego\": {\n",
    "        \"table_id\": 4094,\n",
    "        \"variable_id\": 4098,\n",
    "        \"descrição\": \"Tabela: 4094: Pessoas de 14 anos ou mais de idade, total, na força de trabalho, ocupadas, desocupadas, fora da força de trabalho, em situação de informalidade e respectivas taxas e níveis, por grupo de idade. Variável: 4098:  Nível da desocupação, na semana de referência, das pessoas de 14 anos ou mais de idade (%)\",\n",
    "        },  # Taxa de desemprego\n",
    "}\n",
    "\n",
    "# Loop para buscar todas as séries do IBGE\n",
    "for name, params in ibge_series.items():\n",
    "    print(f\"Baixando série do IBGE: {name} (Tabela: {params['table_id']}, Variável: {params['variable_id']})\")\n",
    "    df = fetch_ibge_series(params['table_id'], params['variable_id'])\n",
    "    df = df.rename(columns={\"valor\": name})\n",
    "    filename = f\"IBGE {name} - T{params['table_id']} - V{params['variable_id']} - {datetime.today().strftime('%Y%m%d%H%M%S')}.csv\"\n",
    "    filename = os.path.join(diretorio_dados, filename)\n",
    "    df.to_csv(filename, index=False)\n",
    "    print(f\"Arquivo salvo: {filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_pib_data(name):\n",
    "    \"\"\"\n",
    "    Busca os dados do PIB trimestral usando a API do IBGE.\n",
    "    \"\"\"\n",
    "    url = \"https://apisidra.ibge.gov.br/values/t/6613/p/all/v/9319/N1/1/c11255/90707\"\n",
    "    response = requests.get(url)\n",
    "    response.raise_for_status()\n",
    "    data = response.json()\n",
    "    print(url)\n",
    "    \n",
    "    # Converter JSON para DataFrame\n",
    "    df = pd.DataFrame(data[1:])  # Ignora o cabeçalho\n",
    "    df['data'] = pd.to_datetime(df['D1C'].str[:4] + '-' + (df['D1C'].str[4:].astype(int) * 3 - 2).astype(str), format='%Y-%m')    \n",
    "    df['PIB'] = pd.to_numeric(df['V'], errors='coerce')\n",
    "    return df[['data', 'PIB']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://apisidra.ibge.gov.br/values/t/6613/p/all/v/9319/N1/1/c11255/90707\n"
     ]
    }
   ],
   "source": [
    "descricao = \"Tabela: 6613: Valores encadeados a preços de 1995 com ajuste sazonal. Variável: 9319:  Valores encadeados a preços de 1995 com ajuste sazonal (Milhões de Reais) - casas decimais: padrão = 2, máximo = 4. Setor: 90707  PIB a preços de mercado\"\n",
    "\n",
    "# Testar a função\n",
    "name = 'PIB Desazonalizado Encadeado 1995'\n",
    "df_pib = fetch_pib_data(name)\n",
    "filename = f\"IBGE {name}  - T6613 - V9319 - {datetime.today().strftime('%Y%m%d%H%M%S')}.csv\"\n",
    "filename = os.path.join(diretorio_dados, filename)\n",
    "\n",
    "# Exportar para CSV (opcional)\n",
    "df_pib.to_csv(filename, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para processar arquivos CSV\n",
    "def plotar_graficos():\n",
    "    sns.set_theme(style=\"whitegrid\")\n",
    "    for arquivo in os.listdir(diretorio_dados):\n",
    "        if arquivo.endswith('.csv'):\n",
    "            caminho_arquivo = os.path.join(diretorio_dados, arquivo)\n",
    "\n",
    "            # Leitura do arquivo CSV\n",
    "            df = pd.read_csv(caminho_arquivo)\n",
    "\n",
    "            # Verifica se as colunas necessárias existem\n",
    "            if 'data' not in df.columns or len(df.columns) < 2:\n",
    "                print(f\"Aviso: O arquivo {arquivo} não contém as colunas necessárias.\")\n",
    "                continue\n",
    "\n",
    "            # Obtém o nome da segunda coluna (que será usada como título e eixo Y)\n",
    "            coluna_dados = df.columns[1]\n",
    "\n",
    "            # Converte a coluna 'data' para datetime para garantir formato correto\n",
    "            df['data'] = pd.to_datetime(df['data'], format='%Y-%m-%d', errors='coerce')\n",
    "\n",
    "            # Remove valores inválidos\n",
    "            df = df.dropna(subset=['data', coluna_dados])\n",
    "\n",
    "            # Nome do arquivo de saída\n",
    "            nome_imagem = f\"{coluna_dados}.png\"\n",
    "            caminho_imagem = os.path.join(diretorio_imagens, nome_imagem)\n",
    "\n",
    "            # Criação do gráfico\n",
    "            plt.figure(figsize=(10, 6))\n",
    "            sns.lineplot(data=df, x='data', y=coluna_dados, marker='o')\n",
    "            plt.title(f\"{coluna_dados}\")\n",
    "            plt.xlabel(\"Data\")\n",
    "            plt.ylabel(coluna_dados)\n",
    "            plt.tight_layout()\n",
    "\n",
    "            # Salvar gráfico\n",
    "            plt.savefig(caminho_imagem, format='png')\n",
    "            plt.close()\n",
    "            print(f\"Gráfico salvo: {caminho_imagem}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gráfico salvo: imagens\\Captação líquida diária de depósitos de poupança - SBPE.png\n",
      "Gráfico salvo: imagens\\Concessões de crédito PF.png\n",
      "Gráfico salvo: imagens\\Inadimplência da carteira de crédito PF.png\n",
      "Gráfico salvo: imagens\\Saldo diário de depósitos de poupança - SBPE e rural.png\n",
      "Gráfico salvo: imagens\\Selic.png\n",
      "Gráfico salvo: imagens\\Spread médio PF.png\n",
      "Gráfico salvo: imagens\\Taxa de Juros PF.png\n",
      "Gráfico salvo: imagens\\Índice de Confiança do Consumidor.png\n",
      "Gráfico salvo: imagens\\Índice nacional de preços ao consumidor-amplo (IPCA).png\n",
      "Gráfico salvo: imagens\\PIB.png\n",
      "Gráfico salvo: imagens\\Índice de Desemprego.png\n"
     ]
    }
   ],
   "source": [
    "plotar_graficos()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datas dos primeiros dias de cada trimestre\n",
    "primeiros_dias_trimestre = [\"01-01\", \"04-01\", \"07-01\", \"10-01\"]\n",
    "\n",
    "# Função para processar arquivos CSV\n",
    "def preencher_dados_faltantes():\n",
    "\n",
    "    # Resetar o logger\n",
    "    reset_logger(logger_name, arquivo_log)\n",
    "\n",
    "    logging.info(\"Logger resetado e iniciado novamente.\")\n",
    "\n",
    "    logging.info(\"Iniciando o processamento dos arquivos CSV.\")\n",
    "\n",
    "    # Itera sobre os arquivos no diretório\n",
    "    for arquivo in os.listdir(diretorio_dados):\n",
    "        if arquivo.endswith(\".csv\"):\n",
    "            caminho_arquivo = os.path.join(diretorio_dados, arquivo)            \n",
    "            logging.info(f\"Processando arquivo: {arquivo}\")\n",
    "\n",
    "            try:\n",
    "                # Leitura do arquivo CSV\n",
    "                df = pd.read_csv(caminho_arquivo)\n",
    "\n",
    "                # Verifica se as colunas necessárias existem\n",
    "                if 'data' not in df.columns:\n",
    "                    logging.warning(f\"O arquivo {arquivo} não contém a coluna 'data'. Ignorado.\")\n",
    "                    continue\n",
    "\n",
    "                # Converte a coluna 'data' para datetime\n",
    "                df['data'] = pd.to_datetime(df['data'], format='%Y-%m-%d', errors='coerce')\n",
    "\n",
    "                # Remove valores inválidos e ordena por data\n",
    "                df = df.dropna(subset=['data']).sort_values(by='data').reset_index(drop=True)\n",
    "\n",
    "                # Garante que o índice é datetime\n",
    "                df.set_index('data', inplace=True)\n",
    "\n",
    "                # Determina os anos com dados no arquivo\n",
    "                anos = df.index.year.unique()\n",
    "\n",
    "                # Processa cada ano\n",
    "                alteracoes = []\n",
    "                for ano in anos:\n",
    "                    for dia in primeiros_dias_trimestre:\n",
    "                        data_trimestre = pd.Timestamp(f\"{ano}-{dia}\")\n",
    "\n",
    "                        if data_trimestre not in df.index:  # Se a data não existe\n",
    "                            # Busca o primeiro dado do trimestre\n",
    "                            inicio_trimestre = pd.Timestamp(f\"{ano}-{dia}\")\n",
    "                            fim_trimestre = inicio_trimestre + pd.offsets.QuarterEnd(0)\n",
    "                            filtro = (df.index >= inicio_trimestre) & (df.index <= fim_trimestre)\n",
    "\n",
    "                            if filtro.any():  # Se houver dados no trimestre\n",
    "                                dado_origem = df.loc[filtro].iloc[0]\n",
    "                                df.loc[data_trimestre] = dado_origem\n",
    "                                alteracoes.append((str(data_trimestre.date()), str(dado_origem.name.date())))\n",
    "\n",
    "                # Ordena novamente o DataFrame após inserir dados\n",
    "                df.sort_index(inplace=True)\n",
    "\n",
    "                # Salva o arquivo CSV atualizado\n",
    "                df.reset_index(inplace=True)\n",
    "\n",
    "                caminho_arquivo_processado = os.path.join(diretorio_dados_processados, 'p'+arquivo)\n",
    "                df.to_csv(caminho_arquivo_processado, index=False)\n",
    "\n",
    "                # Registra alterações no log\n",
    "                for alteracao in alteracoes:\n",
    "                    logging.info(f\"{arquivo} - Data alterada: {alteracao[0]} - Origem: {alteracao[1]}\")\n",
    "\n",
    "                logging.info(f\"Arquivo processado com sucesso: {arquivo}\")\n",
    "\n",
    "            except Exception as e:\n",
    "                logging.error(f\"Erro ao processar o arquivo {arquivo}: {e}\")\n",
    "\n",
    "    logging.info(\"Processamento concluído.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "preencher_dados_faltantes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_csv_files_in_folder(folder_path):\n",
    "    \"\"\"\n",
    "    Escaneia todos os arquivos .csv em uma pasta e faz o merge usando a coluna 'data' como índice.\n",
    "\n",
    "    Args:\n",
    "        folder_path (str): Caminho da pasta onde os arquivos CSV estão armazenados.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame combinado.\n",
    "    \"\"\"\n",
    "    merged_df = None\n",
    "    \n",
    "    # Escanear arquivos na pasta\n",
    "    for file_name in os.listdir(folder_path):\n",
    "        if file_name.endswith('.csv'):\n",
    "            file_path = os.path.join(folder_path, file_name)\n",
    "            print(f\"Lendo arquivo: {file_name}\")\n",
    "            # Carregar o arquivo CSV\n",
    "            df = pd.read_csv(file_path, index_col='data')\n",
    "            \n",
    "            # Merge com o DataFrame principal\n",
    "            if merged_df is None:\n",
    "                merged_df = df\n",
    "            else:\n",
    "                merged_df = merged_df.merge(df, how='inner', left_index=True, right_index=True)\n",
    "\n",
    "            print(f'Quantidade de linhas no arquivo final: {len(merged_df)}')\n",
    "    \n",
    "    return merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lendo arquivo: pBCB Captação líquida diária de depósitos de poupança - SBPE - COD240 - 20241112144804.csv\n",
      "Quantidade de linhas no arquivo final: 6276\n",
      "Lendo arquivo: pBCB Concessões de crédito PF - COD20662 - 20241112144803.csv\n",
      "Quantidade de linhas no arquivo final: 124\n",
      "Lendo arquivo: pBCB Inadimplência da carteira de crédito PF - COD21084 - 20241112144803.csv\n",
      "Quantidade de linhas no arquivo final: 124\n",
      "Lendo arquivo: pBCB Saldo diário de depósitos de poupança - SBPE e rural - COD23 - 20241112144810.csv\n",
      "Quantidade de linhas no arquivo final: 124\n",
      "Lendo arquivo: pBCB Selic - COD11 - 20241112144802.csv\n",
      "Quantidade de linhas no arquivo final: 124\n",
      "Lendo arquivo: pBCB Spread médio PF - COD20809 - 20241112144803.csv\n",
      "Quantidade de linhas no arquivo final: 124\n",
      "Lendo arquivo: pBCB Taxa de Juros PF - COD11 - 20241112144802.csv\n",
      "Quantidade de linhas no arquivo final: 124\n",
      "Lendo arquivo: pBCB Índice de Confiança do Consumidor - COD4393 - 20241112144811.csv\n",
      "Quantidade de linhas no arquivo final: 124\n",
      "Lendo arquivo: pBCB Índice nacional de preços ao consumidor-amplo (IPCA) - COD433 - 20241112144811.csv\n",
      "Quantidade de linhas no arquivo final: 124\n",
      "Lendo arquivo: pIBGE PIB Desazonalizado Encadeado 1995  - T6613 - V9319 - 20241112155514.csv\n",
      "Quantidade de linhas no arquivo final: 54\n",
      "Lendo arquivo: pIBGE Índice de Desemprego - T4094 - V4098 - 20241112144817.csv\n",
      "Quantidade de linhas no arquivo final: 50\n"
     ]
    }
   ],
   "source": [
    "# Chama a função para combinar os arquivos e descartar linhas com dados faltando\n",
    "merged_df = merge_csv_files_in_folder(diretorio_dados_processados).dropna()\n",
    "\n",
    "# Exportar o DataFrame combinado para um arquivo CSV (opcional)\n",
    "merged_df.to_csv(arquivo_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz de correlação salva em: imagens\\matriz_correlacao.png\n"
     ]
    }
   ],
   "source": [
    "# Configurar estilo do seaborn\n",
    "sns.set_theme(style=\"white\")\n",
    "\n",
    "# Criar a pasta de imagens se não existir\n",
    "os.makedirs(diretorio_imagens, exist_ok=True)\n",
    "\n",
    "# Ler o arquivo CSV\n",
    "df = pd.read_csv(arquivo_csv)\n",
    "\n",
    "# Verificar se a coluna 'data' existe e remover antes de calcular a correlação\n",
    "if 'data' in df.columns:\n",
    "    df.drop(columns=['data'], inplace=True)\n",
    "\n",
    "# Calcular a matriz de correlação\n",
    "correlacao = df.corr()\n",
    "\n",
    "# Criar máscara para mostrar apenas o quadrante inferior\n",
    "mask = np.triu(np.ones_like(correlacao, dtype=bool))\n",
    "\n",
    "# Criar o gráfico de correlação\n",
    "plt.figure(figsize=(10, 8))\n",
    "cmap = sns.diverging_palette(230, 20, as_cmap=True)\n",
    "sns.heatmap(\n",
    "    correlacao, \n",
    "    mask=mask, \n",
    "    cmap=cmap, \n",
    "    annot=True, \n",
    "    fmt=\".2f\", \n",
    "    square=True, \n",
    "    cbar_kws={\"shrink\": 0.8}, \n",
    "    linewidths=0.5\n",
    ")\n",
    "\n",
    "# Título opcional\n",
    "plt.title(\"Matriz de Correlação (Quadrante Inferior)\", fontsize=14)\n",
    "\n",
    "# Salvar a imagem em SVG\n",
    "caminho_svg = os.path.join(diretorio_imagens, \"matriz_correlacao.png\")\n",
    "plt.savefig(caminho_svg, format=\"png\",bbox_inches=\"tight\")\n",
    "plt.close()\n",
    "\n",
    "print(f\"Matriz de correlação salva em: {caminho_svg}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gráfico salvo em: imagens\\correlacao_defasada_pib.png\n",
      "Gráfico salvo em: imagens\\correlacao_defasada_selic.png\n"
     ]
    }
   ],
   "source": [
    "# Configurar estilo do seaborn\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "\n",
    "# Ler o arquivo CSV\n",
    "df = pd.read_csv(arquivo_csv)\n",
    "\n",
    "# Verificar se a coluna 'data' existe e removê-la, pois não é necessária para a correlação\n",
    "if 'data' in df.columns:\n",
    "    df.drop(columns=['data'], inplace=True)\n",
    "\n",
    "# Garantir que as colunas SELIC e PIB existem\n",
    "if 'Selic' not in df.columns or 'PIB' not in df.columns:\n",
    "    raise ValueError(\"As colunas 'SELIC' e 'PIB' devem estar presentes no arquivo.\")\n",
    "\n",
    "# Selecionar colunas para análise (todas exceto SELIC e PIB)\n",
    "variaveis = [col for col in df.columns if col not in ['SELIC', 'PIB']]\n",
    "\n",
    "# Função para calcular correlação defasada\n",
    "def calcular_correlacao_defasada(df, referencia, variaveis, max_defasagem):\n",
    "    \"\"\"\n",
    "    Calcula a correlação defasada entre uma variável de referência e outras variáveis.\n",
    "    \n",
    "    Parameters:\n",
    "        df (pd.DataFrame): DataFrame com os dados.\n",
    "        referencia (str): Nome da variável de referência.\n",
    "        variaveis (list): Lista de variáveis para correlacionar com a referência.\n",
    "        max_defasagem (int): Máxima defasagem (positiva e negativa) para calcular.\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: Matriz de correlação defasada.\n",
    "    \"\"\"\n",
    "    correlacoes = pd.DataFrame(index=range(-max_defasagem, max_defasagem + 1), columns=variaveis)\n",
    "\n",
    "    for lag in range(-max_defasagem, max_defasagem + 1):\n",
    "        for var in variaveis:\n",
    "            # Aplicar defasagem à variável de referência\n",
    "            if lag < 0:\n",
    "                correlacoes.loc[lag, var] = df[referencia].shift(-lag).corr(df[var])\n",
    "            else:\n",
    "                correlacoes.loc[lag, var] = df[referencia].shift(lag).corr(df[var])\n",
    "\n",
    "    return correlacoes.astype(float)\n",
    "\n",
    "# Máxima defasagem\n",
    "max_defasagem = 4\n",
    "\n",
    "# Calcular correlação defasada para PIB e SELIC\n",
    "correlacao_pib = calcular_correlacao_defasada(df, 'PIB', variaveis, max_defasagem)\n",
    "correlacao_selic = calcular_correlacao_defasada(df, 'Selic', variaveis, max_defasagem)\n",
    "\n",
    "# Função para plotar e salvar a matriz de correlação defasada\n",
    "def plotar_matriz_correlacao(correlacoes, titulo, nome_arquivo):\n",
    "    plt.figure(figsize=(12, 8))\n",
    "\n",
    "    # Substituir valores ausentes por 0 ou outro valor\n",
    "    correlacoes = correlacoes.fillna(0).T  # Transpor para inverter os eixos\n",
    "\n",
    "    sns.heatmap(\n",
    "        correlacoes,\n",
    "        cmap=\"coolwarm\",\n",
    "        annot=True,\n",
    "        fmt=\".2f\",\n",
    "        cbar_kws={\"shrink\": 0.8},\n",
    "        linewidths=0.5\n",
    "    )\n",
    "    plt.title(titulo, fontsize=16)\n",
    "    plt.xlabel(\"Defasagem\")\n",
    "    plt.ylabel(\"Variáveis\")\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Salvar a matriz como SVG\n",
    "    caminho_svg = os.path.join(diretorio_imagens, nome_arquivo)\n",
    "    plt.savefig(caminho_svg, format=\"png\", bbox_inches=\"tight\")\n",
    "    plt.close()\n",
    "    print(f\"Gráfico salvo em: {caminho_svg}\")\n",
    "\n",
    "# Plotar e salvar as matrizes de correlação defasada\n",
    "plotar_matriz_correlacao(correlacao_pib, \"Matriz de Correlação Defasada (PIB)\", \"correlacao_defasada_pib.png\")\n",
    "plotar_matriz_correlacao(correlacao_selic, \"Matriz de Correlação Defasada (SELIC)\", \"correlacao_defasada_selic.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "udata-observatorio-6hlLqOE9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
