{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "path = \"dados/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para buscar dados da API do Banco Central\n",
    "def fetch_bcb_series(series_code, start_date, end_date=None):\n",
    "    \"\"\"\n",
    "    Busca uma série do Banco Central do Brasil usando a API SGS.\n",
    "    \n",
    "    Args:\n",
    "        series_code (int): Código da série.\n",
    "        start_date (str): Data de início no formato DD/MM/AAAA.\n",
    "        end_date (str): Data de fim no formato DD/MM/AAAA (default: hoje).\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame com as datas e valores da série.\n",
    "    \"\"\"\n",
    "    if end_date is None:\n",
    "        end_date = datetime.today().strftime('%d/%m/%Y')\n",
    "    \n",
    "    url = f\"https://api.bcb.gov.br/dados/serie/bcdata.sgs.{series_code}/dados\"\n",
    "    params = {\"formato\": \"json\", \"dataInicial\": start_date, \"dataFinal\": end_date}\n",
    "    print(url)\n",
    "    print(params)\n",
    "    response = requests.get(url, params=params)\n",
    "    response.raise_for_status()\n",
    "    \n",
    "    data = response.json()\n",
    "    df = pd.DataFrame(data)\n",
    "    df['data'] = pd.to_datetime(df['data'], format='%d/%m/%Y')\n",
    "    df['valor'] = pd.to_numeric(df['valor'], errors='coerce')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para buscar dados da API do IBGE (SIDRA)\n",
    "def fetch_ibge_series(table_id, variable_id, period=\"all\"):\n",
    "    \"\"\"\n",
    "    Busca dados do IBGE usando a API SIDRA.\n",
    "    \n",
    "    Args:\n",
    "        table_id (int): Código da tabela no SIDRA.\n",
    "        variable_id (int): Código da variável na tabela.\n",
    "        period (str): Período de busca (default: \"all\").\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame com os dados da série.\n",
    "    \"\"\"\n",
    "    url = f\"https://apisidra.ibge.gov.br/values/t/{table_id}/v/{variable_id}/p/{period}/N1/1\"\n",
    "    response = requests.get(url)\n",
    "    response.raise_for_status()\n",
    "    data = response.json()\n",
    "    print(url)\n",
    "    \n",
    "    # Converter JSON para DataFrame\n",
    "    df = pd.DataFrame(data[1:])  # Ignora o cabeçalho\n",
    "    df['data'] = pd.to_datetime(df['D2C'].str[:4] + '-' + (df['D2C'].str[4:].astype(int) * 3 - 2).astype(str), format='%Y-%m')\n",
    "    df['valor'] = pd.to_numeric(df['V'], errors='coerce')\n",
    "    return df[['data', 'valor']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_pib_data():\n",
    "    \"\"\"\n",
    "    Busca os dados do PIB trimestral usando a API do IBGE.\n",
    "    \"\"\"\n",
    "    url = \"https://servicodados.ibge.gov.br/api/v3/agregados/6613/periodos/199601|199602|199603|199604|199701|199702|199703|199704|199801|199802|199803|199804|199901|199902|199903|199904|200001|200002|200003|200004|200101|200102|200103|200104|200201|200202|200203|200204|200301|200302|200303|200304|200401|200402|200403|200404|200501|200502|200503|200504|200601|200602|200603|200604|200701|200702|200703|200704|200801|200802|200803|200804|200901|200902|200903|200904|201001|201002|201003|201004|201101|201102|201103|201104|201201|201202|201203|201204|201301|201302|201303|201304|201401|201402|201403|201404|201501|201502|201503|201504|201601|201602|201603|201604|201701|201702|201703|201704|201801|201802|201803|201804|201901|201902|201903|201904|202001|202002|202003|202004|202101|202102|202103|202104|202201|202202|202203|202204|202301|202302|202303|202304|202401|202402/variaveis/9319?localidades=N1[all]&classificacao=11255[90707]\"\n",
    "    \n",
    "    response = requests.get(url)\n",
    "    response.raise_for_status()\n",
    "    \n",
    "    data = response.json()\n",
    "    \n",
    "    # Estruturar os dados no DataFrame\n",
    "    results = []\n",
    "    for entry in data[0]['resultados']:\n",
    "        for serie in entry['series']:\n",
    "            for value in serie['serie'].items():\n",
    "                period, pib_value = value\n",
    "                results.append({'periodo': period, 'pib': float(pib_value)})\n",
    "    \n",
    "    df = pd.DataFrame(results)\n",
    "    \n",
    "    # Converter o período para formato datetime\n",
    "    df['data'] = pd.to_datetime(df['periodo'].str[:4] + '-' + (df['periodo'].str[4:].astype(int) * 3 - 2).astype(str), format='%Y-%m')\n",
    "    df = df.drop(columns=['periodo'])  # Opcional: remover coluna original\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lista de séries do BCB e seus códigos\n",
    "bcb_series = [\n",
    "    { \n",
    "        \"Nome\": \"Selic\",\n",
    "        \"Descrição\" : \"Taxa de juros que representa a taxa média ajustada das operações compromissadas com prazo de um dia útil lastreadas com títulos públicos federais custodiados no Sistema Especial de Liquidação e de Custódia (Selic). Divulgação em % a.d.\",\n",
    "        \"Série\": 11,\n",
    "    },\n",
    "    { \n",
    "        \"Nome\": \"Taxa de Juros PF\",\n",
    "        \"Descrição\" : \"Taxa de juros que representa a taxa média ajustada das operações compromissadas com prazo de um dia útil lastreadas com títulos públicos federais custodiados no Sistema Especial de Liquidação e de Custódia (Selic). Divulgação em % a.d.\",\n",
    "        \"Série\": 11,\n",
    "    },\n",
    "    {\n",
    "        \"Nome\": \"Spread médio PF\",\n",
    "        \"Descrição\": \"Diferença entre a taxa média de juros das novas operações de crédito livre contratadas no período de referência e o custo de captação referencial médio. Não inclui operações referenciadas em taxas regulamentadas, operações vinculadas a recursos do Banco Nacional de Desenvolvimento Econômico e Social (BNDES) ou quaisquer outras lastreadas em recursos compulsórios ou governamentais.\",\n",
    "        \"Série\": 20809,\n",
    "    },\n",
    "    {\n",
    "        \"Nome\": \"Concessões de crédito PF\",\n",
    "        \"Descrição\": \"Conceito: Valor das novas operações de crédito contratadas no período de referência com taxas de juros livremente pactuadas entre mutuários e instituições financeiras. Não inclui operações referenciadas em taxas regulamentadas, operações vinculadas a recursos do Banco Nacional de Desenvolvimento Econômico e Social (BNDES) ou quaisquer outras lastreadas em recursos compulsórios ou governamentais.\",\n",
    "        \"Série\": 20662,\n",
    "    },\n",
    "    {\n",
    "        \"Nome\": \"\tInadimplência da carteira de crédito PF\",\n",
    "        \"Descrição\": \"Conceito: Percentual da carteira de crédito do Sistema Financeiro Nacional com pelo menos uma parcela com atraso superior a 90 dias. Inclui operações contratadas no segmento de crédito livre e no segmento de crédito direcionado.\",\n",
    "        \"Série\": 21084,\n",
    "    },\n",
    "    {\n",
    "        \"Nome\": \"Captação líquida diária de depósitos de poupança - SBPE\",\n",
    "        \"Descrição\": \"A captação líquida é representada pela soma das aplicações e dos rendimentos creditados, excluindo-se as retiradas\",\n",
    "        \"Série\": 240,\n",
    "    },\n",
    "    {\n",
    "        \"Nome\": \"Saldo diário de depósitos de poupança - SBPE e rural\",\n",
    "        \"Descrição\": \"Saldo diário de depósitos de poupança - SBPE e rural\",\n",
    "        \"Série\": 23,\n",
    "    },\n",
    "    {\n",
    "        \"Nome\": \"Índice de Confiança do Consumidor\",\n",
    "        \"Descrição\": \"O Índice de Confiança do Consumidor (ICC) busca identificar o sentimento dos consumidores relativo às suas condições financeiras, às suas perspectivas futuras e também a percepção que o consumidor tem das condições econômicas do país.\",\n",
    "        \"Série\": 4393,\n",
    "    },\n",
    "    {\n",
    "        \"Nome\": \"Índice nacional de preços ao consumidor-amplo (IPCA)\",\n",
    "        \"Descrição\": \"O IPCA tem por objetivo medir a inflação de um conjunto de produtos e serviços comercializados no varejo, referentes ao consumo pessoal das famílias. Para garantir uma cobertura de 90% das famílias das áreas urbanas do País, abrange atualmente aquelas com rendimentos de 1 a 40 salários mínimos nas regiões metropolitanas de Belém, Fortaleza, Recife, Salvador, Belo Horizonte, Vitória, Rio de Janeiro, São Paulo, Curitiba e Porto Alegre, além do Distrito Federal e dos municípios de Goiânia, Campo Grande, Rio Branco, São Luís e Aracaju. \",\n",
    "        \"Série\": 433,\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baixando série do BCB: Selic (Código: 11)\n",
      "https://api.bcb.gov.br/dados/serie/bcdata.sgs.11/dados\n",
      "{'formato': 'json', 'dataInicial': '01/01/2000', 'dataFinal': '12/11/2024'}\n"
     ]
    },
    {
     "ename": "JSONDecodeError",
     "evalue": "Expecting value: line 1 column 1 (char 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\acarm\\.virtualenvs\\udata-observatorio-vkfxd7dX\\Lib\\site-packages\\requests\\models.py:974\u001b[0m, in \u001b[0;36mResponse.json\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m    973\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 974\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcomplexjson\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloads\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    975\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m JSONDecodeError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    976\u001b[0m     \u001b[38;5;66;03m# Catch JSON-related errors and raise as requests.JSONDecodeError\u001b[39;00m\n\u001b[0;32m    977\u001b[0m     \u001b[38;5;66;03m# This aliases json.JSONDecodeError and simplejson.JSONDecodeError\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\json\\__init__.py:346\u001b[0m, in \u001b[0;36mloads\u001b[1;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[0;32m    343\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[0;32m    344\u001b[0m         parse_int \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m parse_float \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[0;32m    345\u001b[0m         parse_constant \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_pairs_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kw):\n\u001b[1;32m--> 346\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_default_decoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    347\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\json\\decoder.py:337\u001b[0m, in \u001b[0;36mJSONDecoder.decode\u001b[1;34m(self, s, _w)\u001b[0m\n\u001b[0;32m    333\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Return the Python representation of ``s`` (a ``str`` instance\u001b[39;00m\n\u001b[0;32m    334\u001b[0m \u001b[38;5;124;03mcontaining a JSON document).\u001b[39;00m\n\u001b[0;32m    335\u001b[0m \n\u001b[0;32m    336\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m--> 337\u001b[0m obj, end \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraw_decode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_w\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mend\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    338\u001b[0m end \u001b[38;5;241m=\u001b[39m _w(s, end)\u001b[38;5;241m.\u001b[39mend()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\json\\decoder.py:355\u001b[0m, in \u001b[0;36mJSONDecoder.raw_decode\u001b[1;34m(self, s, idx)\u001b[0m\n\u001b[0;32m    354\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m--> 355\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m JSONDecodeError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpecting value\u001b[39m\u001b[38;5;124m\"\u001b[39m, s, err\u001b[38;5;241m.\u001b[39mvalue) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    356\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m obj, end\n",
      "\u001b[1;31mJSONDecodeError\u001b[0m: Expecting value: line 1 column 1 (char 0)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 9\u001b[0m\n\u001b[0;32m      7\u001b[0m code \u001b[38;5;241m=\u001b[39m item[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSérie\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBaixando série do BCB: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m (Código: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcode\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 9\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mfetch_bcb_series\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart_date\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m df \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mrename(columns\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalor\u001b[39m\u001b[38;5;124m\"\u001b[39m: name})\n\u001b[0;32m     11\u001b[0m filename \u001b[38;5;241m=\u001b[39m path\u001b[38;5;241m+\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbcb \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcode\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdatetime\u001b[38;5;241m.\u001b[39mtoday()\u001b[38;5;241m.\u001b[39mstrftime(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mY\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mm\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mH\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mM\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mS\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "Cell \u001b[1;32mIn[7], line 24\u001b[0m, in \u001b[0;36mfetch_bcb_series\u001b[1;34m(series_code, start_date, end_date)\u001b[0m\n\u001b[0;32m     21\u001b[0m response \u001b[38;5;241m=\u001b[39m requests\u001b[38;5;241m.\u001b[39mget(url, params\u001b[38;5;241m=\u001b[39mparams)\n\u001b[0;32m     22\u001b[0m response\u001b[38;5;241m.\u001b[39mraise_for_status()\n\u001b[1;32m---> 24\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjson\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     25\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(data)\n\u001b[0;32m     26\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mto_datetime(df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m'\u001b[39m], \u001b[38;5;28mformat\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mm/\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mY\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\acarm\\.virtualenvs\\udata-observatorio-vkfxd7dX\\Lib\\site-packages\\requests\\models.py:978\u001b[0m, in \u001b[0;36mResponse.json\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m    974\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m complexjson\u001b[38;5;241m.\u001b[39mloads(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtext, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    975\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m JSONDecodeError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    976\u001b[0m     \u001b[38;5;66;03m# Catch JSON-related errors and raise as requests.JSONDecodeError\u001b[39;00m\n\u001b[0;32m    977\u001b[0m     \u001b[38;5;66;03m# This aliases json.JSONDecodeError and simplejson.JSONDecodeError\u001b[39;00m\n\u001b[1;32m--> 978\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m RequestsJSONDecodeError(e\u001b[38;5;241m.\u001b[39mmsg, e\u001b[38;5;241m.\u001b[39mdoc, e\u001b[38;5;241m.\u001b[39mpos)\n",
      "\u001b[1;31mJSONDecodeError\u001b[0m: Expecting value: line 1 column 1 (char 0)"
     ]
    }
   ],
   "source": [
    "# Data inicial para busca\n",
    "start_date = \"01/01/2000\"\n",
    "\n",
    "# Loop para buscar todas as séries do BCB\n",
    "for item in bcb_series:\n",
    "    name = item[\"Nome\"]\n",
    "    code = item[\"Série\"]\n",
    "    print(f\"Baixando série do BCB: {name} (Código: {code})\")\n",
    "    df = fetch_bcb_series(code, start_date)\n",
    "    df = df.rename(columns={\"valor\": name})\n",
    "    filename = path+ f\"bcb {name} {code} {datetime.today().strftime('%Y%m%d%H%M%S')}.csv\"\n",
    "    df.to_csv(filename, index=False, sep=\";\")\n",
    "    print(f\"Arquivo salvo: {filename}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#/T/  Tabela:  \t6613 - \tValores encadeados a preços de 1995 com ajuste sazonal\n",
    "#9319  Valores encadeados a preços de 1995 com ajuste sazonal (Milhões de Reais) - casas decimais: padrão = 2, máximo = 4\n",
    "# 90707  PIB a preços de mercado\n",
    "\n",
    "def fetch_pib_data():\n",
    "    \"\"\"\n",
    "    Busca os dados do PIB trimestral usando a API do IBGE.\n",
    "    \"\"\"\n",
    "    url = \"https://servicodados.ibge.gov.br/api/v3/agregados/6613/periodos/199601|199602|199603|199604|199701|199702|199703|199704|199801|199802|199803|199804|199901|199902|199903|199904|200001|200002|200003|200004|200101|200102|200103|200104|200201|200202|200203|200204|200301|200302|200303|200304|200401|200402|200403|200404|200501|200502|200503|200504|200601|200602|200603|200604|200701|200702|200703|200704|200801|200802|200803|200804|200901|200902|200903|200904|201001|201002|201003|201004|201101|201102|201103|201104|201201|201202|201203|201204|201301|201302|201303|201304|201401|201402|201403|201404|201501|201502|201503|201504|201601|201602|201603|201604|201701|201702|201703|201704|201801|201802|201803|201804|201901|201902|201903|201904|202001|202002|202003|202004|202101|202102|202103|202104|202201|202202|202203|202204|202301|202302|202303|202304|202401|202402/variaveis/9319?localidades=N1[all]&classificacao=11255[90707]\"\n",
    "    \n",
    "    response = requests.get(url)\n",
    "    response.raise_for_status()\n",
    "    \n",
    "    data = response.json()\n",
    "    \n",
    "    # Estruturar os dados no DataFrame\n",
    "    results = []\n",
    "    for entry in data[0]['resultados']:\n",
    "        for serie in entry['series']:\n",
    "            for value in serie['serie'].items():\n",
    "                period, pib_value = value\n",
    "                results.append({'periodo': period, 'pib': float(pib_value)})\n",
    "    \n",
    "    df = pd.DataFrame(results)\n",
    "    \n",
    "    # Converter o período para formato datetime\n",
    "    df['data'] = pd.to_datetime(df['periodo'], format='%Y%m')\n",
    "    df = df.drop(columns=['periodo'])  # Opcional: remover coluna original\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baixando série do IBGE: PIB_Mensal (Tabela: 1620, Variável: 583)\n",
      "https://apisidra.ibge.gov.br/values/t/1620/v/583/p/all/N1/1\n",
      "Arquivo salvo: ibge PIB_Mensal 20241111145146.csv\n",
      "Baixando série do IBGE: Indice_Desemprego (Tabela: 4094, Variável: 4110)\n",
      "https://apisidra.ibge.gov.br/values/t/4094/v/4110/p/all/N1/1\n",
      "Arquivo salvo: ibge Indice_Desemprego 20241111145148.csv\n"
     ]
    }
   ],
   "source": [
    "#/T/  Tabela:  \t1620 - \tSérie encadeada do índice de volume trimestral (Base: média 1995 = 100)\n",
    "#583  Série encadeada do índice de volume trimestral (Base: média 1995 = 100) (Número-índice) - casas decimais: padrão = 2, máximo = 4\n",
    "\n",
    "#/T/  Tabela:  \t4094 - \tPessoas de 14 anos ou mais de idade, total, na força de trabalho, ocupadas, desocupadas, fora da força de trabalho, em situação de informalidade e respectivas taxas e níveis, por grupo de idade\n",
    "# 4110  Distribuição percentual das pessoas de 14 anos ou mais de idade, desocupadas na semana de referência (%) - casas decimais: padrão = 1, máximo = 1\n",
    "\n",
    "# Lista de séries do IBGE e suas tabelas/variáveis\n",
    "ibge_series = {\n",
    "    \"PIB_Trimestral\": {\"table_id\": 1620, \"variable_id\": 583},  # PIB mensal (exemplo)\n",
    "    \"Indice_Desemprego\": {\"table_id\": 4094, \"variable_id\": 4110},  # Taxa de desemprego\n",
    "}\n",
    "\n",
    "# Loop para buscar todas as séries do IBGE\n",
    "for name, params in ibge_series.items():\n",
    "    print(f\"Baixando série do IBGE: {name} (Tabela: {params['table_id']}, Variável: {params['variable_id']})\")\n",
    "    df = fetch_ibge_series(params['table_id'], params['variable_id'])\n",
    "    df = df.rename(columns={\"valor\": name})\n",
    "    filename = f\"ibge {name} {datetime.today().strftime('%Y%m%d%H%M%S')}.csv\"\n",
    "    df.to_csv(filename, index=False, sep=\";\")\n",
    "    print(f\"Arquivo salvo: {filename}\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testar a função\n",
    "df_pib = fetch_pib_data()\n",
    "name = 'PIB Desazonalizado Encadeado 1995'\n",
    "filename = f\"ibge {name} {datetime.today().strftime('%Y%m%d%H%M%S')}.csv\"\n",
    "\n",
    "# Exportar para CSV (opcional)\n",
    "df_pib.to_csv(filename, index=False, sep=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_csv_files_in_folder(folder_path):\n",
    "    \"\"\"\n",
    "    Escaneia todos os arquivos .csv em uma pasta e faz o merge usando a coluna 'data' como índice.\n",
    "\n",
    "    Args:\n",
    "        folder_path (str): Caminho da pasta onde os arquivos CSV estão armazenados.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame combinado.\n",
    "    \"\"\"\n",
    "    merged_df = None\n",
    "    \n",
    "    # Escanear arquivos na pasta\n",
    "    for file_name in os.listdir(folder_path):\n",
    "        if file_name.endswith('.csv'):\n",
    "            file_path = os.path.join(folder_path, file_name)\n",
    "            print(f\"Lendo arquivo: {file_name}\")\n",
    "            # Carregar o arquivo CSV\n",
    "            df = pd.read_csv(file_path, sep=';', parse_dates=['data'], index_col='data')\n",
    "            \n",
    "            # Merge com o DataFrame principal\n",
    "            if merged_df is None:\n",
    "                merged_df = df\n",
    "            else:\n",
    "                merged_df = merged_df.merge(df, how='outer', left_index=True, right_index=True)\n",
    "    \n",
    "    return merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lendo arquivo: bcb Captacao_Liquida_Poupanca 240 20241111143737.csv\n",
      "Lendo arquivo: bcb Confiança_Consumidor 4393 20241111143738.csv\n",
      "Lendo arquivo: bcb Inadimplencia_PF 21084 20241111143731.csv\n",
      "Lendo arquivo: bcb IPCA 433 20241111143739.csv\n",
      "Lendo arquivo: bcb Saldo_Credito_PF 20634 20241111143730.csv\n",
      "Lendo arquivo: bcb Saldo_Poupanca 7836 20241111143738.csv\n",
      "Lendo arquivo: bcb Selic_Meta 432 20241111143730.csv\n",
      "Lendo arquivo: bcb Taxa_Juros_PF 20786 20241111143730.csv\n",
      "Lendo arquivo: ibge PIB Desazonalizado Encadeado 1995 20241111150336.csv\n"
     ]
    }
   ],
   "source": [
    "# Caminho da pasta onde os arquivos CSV estão armazenados\n",
    "folder_path = \"./\"  # Atualize se necessário\n",
    "\n",
    "# Chama a função para combinar os arquivos e descartar linhas com dados faltando\n",
    "merged_df = merge_csv_files_in_folder(folder_path).dropna()\n",
    "\n",
    "# Exportar o DataFrame combinado para um arquivo CSV (opcional)\n",
    "merged_df.to_csv(\"merged_data.csv\", sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz de correlação gerada: correlation_matrix_with_numbers.html\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import plotly.figure_factory as ff\n",
    "import plotly.graph_objects as go\n",
    "import plotly.io as pio\n",
    "\n",
    "# Carregar os dados\n",
    "file_path = \"merged_data.csv\"\n",
    "merged_data = pd.read_csv(file_path, sep=';', parse_dates=['data'], index_col='data')\n",
    "\n",
    "# Renomear colunas para nomes mais descritivos\n",
    "renamed_columns = {\n",
    "    \"Taxa_Juros_PF\": \"Taxa Juros (PF)\",\n",
    "    \"Saldo_Credito_PF\": \"Crédito PF\",\n",
    "    \"Inadimplencia_PF\": \"Inadimplência PF\",\n",
    "    \"Captacao_Liquida_Poupanca\": \"Captação Poupança\",\n",
    "    \"Saldo_Poupanca\": \"Saldo Poupança\",\n",
    "    \"Selic_Meta\": \"Taxa Selic\",\n",
    "    \"Confiança_Consumidor\": \"Confiança Consumidor\",\n",
    "    \"IPCA\": \"Inflação (IPCA)\",\n",
    "    \"pib\": \"PIB\"\n",
    "}\n",
    "merged_data.rename(columns=renamed_columns, inplace=True)\n",
    "\n",
    "# Gerar matriz de correlação\n",
    "correlation_matrix = merged_data.corr().round(2)\n",
    "\n",
    "# Criar heatmap da matriz de correlação com valores numéricos\n",
    "fig_corr = go.Figure(\n",
    "    data=go.Heatmap(\n",
    "        z=correlation_matrix.values,\n",
    "        x=correlation_matrix.columns,\n",
    "        y=correlation_matrix.index,\n",
    "        colorscale=\"Viridis\",\n",
    "        zmin=-1,\n",
    "        zmax=1,\n",
    "        colorbar=dict(title=\"Correlation\"),\n",
    "        text=correlation_matrix.values,  # Adicionar os valores numéricos\n",
    "        hoverinfo=\"text\"  # Exibir valores ao passar o mouse\n",
    "    )\n",
    ")\n",
    "\n",
    "# Adicionar os números sobre as células\n",
    "for i, row in enumerate(correlation_matrix.values):\n",
    "    for j, value in enumerate(row):\n",
    "        fig_corr.add_trace(\n",
    "            go.Scatter(\n",
    "                x=[correlation_matrix.columns[j]],\n",
    "                y=[correlation_matrix.index[i]],\n",
    "                text=[f\"{value:.2f}\"],  # Formatar com duas casas decimais\n",
    "                mode=\"text\",\n",
    "                showlegend=False,\n",
    "                textfont=dict(color=\"white\" if abs(value) > 0.5 else \"black\")\n",
    "            )\n",
    "        )\n",
    "\n",
    "# Configurar layout do heatmap\n",
    "fig_corr.update_layout(\n",
    "    title=\"Matriz de Correlação - Variáveis Renomeadas\",\n",
    "    xaxis_title=\"Variáveis\",\n",
    "    yaxis_title=\"Variáveis\",\n",
    "    xaxis=dict(tickangle=-45),\n",
    "    hovermode=\"closest\"\n",
    ")\n",
    "\n",
    "# Salvar matriz de correlação como HTML\n",
    "output_corr_file = \"correlation_matrix_with_numbers.html\"\n",
    "pio.write_html(fig_corr, output_corr_file)\n",
    "\n",
    "# Confirmar os arquivos gerados\n",
    "print(f\"Matriz de correlação gerada: {output_corr_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gráfico interativo gerado e salvo como: normalized_data_plot_with_buttons.html\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import plotly.graph_objects as go\n",
    "import plotly.io as pio\n",
    "\n",
    "# Caminho do arquivo CSV\n",
    "file_path = \"merged_data.csv\"\n",
    "\n",
    "# Carregar os dados do arquivo\n",
    "merged_data = pd.read_csv(file_path, sep=';', parse_dates=['data'], index_col='data')\n",
    "\n",
    "# Remover colunas ou linhas com valores ausentes, se necessário\n",
    "merged_data = merged_data.dropna()\n",
    "\n",
    "# Normalizar os dados\n",
    "scaler = MinMaxScaler()\n",
    "normalized_data = pd.DataFrame(\n",
    "    scaler.fit_transform(merged_data),\n",
    "    index=merged_data.index,\n",
    "    columns=merged_data.columns\n",
    ")\n",
    "\n",
    "# Criar o gráfico interativo com Plotly\n",
    "fig = go.Figure()\n",
    "\n",
    "# Adicionar todas as séries como curvas individuais\n",
    "for column in normalized_data.columns:\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=normalized_data.index,\n",
    "            y=normalized_data[column],\n",
    "            mode='lines',\n",
    "            name=column\n",
    "        )\n",
    "    )\n",
    "\n",
    "# Adicionar botões para manipular a visibilidade\n",
    "button_all = dict(\n",
    "    label=\"Mostrar Todas\",\n",
    "    method=\"update\",\n",
    "    args=[{\"visible\": [True] * len(normalized_data.columns)},  # Mostrar todas as curvas\n",
    "          {\"title\": \"Dados Normalizados - Todas as Curvas Visíveis\"}]\n",
    ")\n",
    "\n",
    "button_none = dict(\n",
    "    label=\"Ocultar Todas\",\n",
    "    method=\"update\",\n",
    "    args=[{\"visible\": [\"legendonly\"] * len(normalized_data.columns)},  # Ocultar todas, mas manter na legenda\n",
    "          {\"title\": \"Dados Normalizados - Nenhuma Curva Visível\"}]\n",
    ")\n",
    "\n",
    "# Atualizar o layout para incluir os botões\n",
    "fig.update_layout(\n",
    "    title=\"Dados Normalizados - Adicione ou Remova Curvas\",\n",
    "    xaxis_title=\"Data\",\n",
    "    yaxis_title=\"Valores Normalizados\",\n",
    "    legend_title=\"Variáveis\",\n",
    "    hovermode=\"x unified\",\n",
    "    updatemenus=[dict(\n",
    "        type=\"buttons\",\n",
    "        direction=\"left\",\n",
    "        buttons=[button_all, button_none],\n",
    "        showactive=True,\n",
    "        x=0.1,\n",
    "        y=1.1\n",
    "    )]\n",
    ")\n",
    "\n",
    "# Salvar o gráfico como HTML\n",
    "output_file = \"normalized_data_plot_with_buttons.html\"\n",
    "pio.write_html(fig, output_file)\n",
    "\n",
    "# Exibir confirmação\n",
    "print(f\"Gráfico interativo gerado e salvo como: {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "udata-observatorio-vkfxd7dX",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
